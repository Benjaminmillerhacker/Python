
         /_        _\   /_        _\
        // \      / \\ // \      / \\
        |\__\    /__/| |\__\    /__/|
         \    ||    /   \    ||    /
          \        /     \        /
           \  __  /       \  __  /
   .-""""-. '.__.'.-""""-. '.__.'.-""""-.  /      
 /_        _\|  /_        _\|  /_        _\
// \      / \\ // \      / \\ // \      / \\
|\__\    /__/| |\__\    /__/| |\__\    /__/|
 \    ||    /   \    ||    /   \    ||    /
  \        /     \        /     \        /
   \  __  /       \  __  /       \  __  /
    '.__.'         '.__.'         '.__.'

   ğŸ…°ğŸ…»ğŸ…¸ğŸ…´ğŸ…½ ğŸ…¿ğŸ…°ğŸ†‚ğŸ†‚ğŸ††ğŸ…¾ğŸ†ğŸ…³ ğŸ…±ğŸ†ğŸ†„ğŸ†ƒğŸ…´ğŸ† 







import urllib2
import threading
import Queue
import urllib
threads = 50
target_url = "http://testphp.vulnweb.com"
wordlist_file = "/tmp/all.txt" # from SVNDigger
resume = None
user_agent = "Mozilla/5.0 (X11; Linux x86_64; rv:19.0) Gecko/20100101Â¬
 Firefox/19.0"
def build_wordlist(wordlist_file):
 # read in the word list
ïµ fd = open(wordlist_file,"rb")
 raw_words = fd.readlines()
 fd.close()

 found_resume = False
 words = Queue.Queue()

ï¶ for word in raw_words:

 word = word.rstrip()

 if resume is not None:

 if found_resume:
 words.put(word)
 else:
 if word == resume:
 found_resume = True
 print "Resuming wordlist from: %s" % resume

 else:
 words.put(word)

 return words

 def dir_bruter(word_queue,extensions=None):

 while not word_queue.empty():
 attempt = word_queue.get()

 attempt_list = []

 # check to see if there is a file extension; if not,
 # it's a directory path we're bruting
ïµ if "." not in attempt:
 attempt_list.append("/%s/" % attempt)
 else:
 attempt_list.append("/%s" % attempt)

 # if we want to bruteforce extensions
ï¶ if extensions:
 for extension in extensions:
 attempt_list.append("/%s%s" % (attempt,extension))

 # iterate over our list of attempts
 for brute in attempt_list:

 url = "%s%s" % (target_url,urllib.quote(brute))

 try:
 headers = {}
ï· headers["User-Agent"] = user_agent
 r = urllib2.Request(url,headers=headers)


 response = urllib2.urlopen(r)

ï¸ if len(response.read()):
 print "[%d] => %s" % (response.code,url)

 except urllib2.URLError,e:
 if hasattr(e, 'code') and e.code != 404:
ï¹ print "!!! %d => %s" % (e.code,url)

 pass
